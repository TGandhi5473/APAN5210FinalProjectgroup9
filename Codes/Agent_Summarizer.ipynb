{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"our-key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent to summarize travel reviews and results\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizerAgent:\n",
    "    def __init__(self, model_id: str = \"gpt-3.5-turbo\"):\n",
    "        # Initialize the Agno Agent\n",
    "        self.agent = Agent(\n",
    "            model=OpenAIChat(id=model_id),\n",
    "            description=\"You are a travel summarizer agent. Summarize travel reviews or travel information concisely based on the requested style.\",\n",
    "            markdown=True\n",
    "        )\n",
    "\n",
    "    def summarize(self, text: str, style: str = \"bullet\") -> str:\n",
    "        \"\"\"Summarize the input text according to the requested style: bullet, paragraph, or headline.\"\"\"\n",
    "        if style == \"bullet\":\n",
    "            prompt = f\"Summarize the following travel review into concise bullet points:\\n\\n{text}\"\n",
    "        elif style == \"headline\":\n",
    "            prompt = f\"Summarize the following travel review as a short, catchy headline:\\n\\n{text}\"\n",
    "        else:\n",
    "            prompt = f\"Summarize the following travel review into a brief paragraph:\\n\\n{text}\"\n",
    "\n",
    "        return self.agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Error from OpenAI API: The api_key client option must be set either by passing api_key to the client or by\n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Error from OpenAI API: The api_key client option must be set either by passing api_key to the client or by\n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Attempt <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> failed: The api_key client option must be set either by passing api_key to the client or by   \n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mWARNING \u001b[0m Attempt \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m failed: The api_key client option must be set either by passing api_key to the client or by   \n",
       "         setting the OPENAI_API_KEY environment variable                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Failed after <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> attempts. Last error using <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChat</span><span style=\"font-weight: bold\">(</span>gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>-turbo<span style=\"font-weight: bold\">)</span>                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Failed after \u001b[1;36m1\u001b[0m attempts. Last error using \u001b[1;35mOpenAIChat\u001b[0m\u001b[1m(\u001b[0mgpt-\u001b[1;36m3.5\u001b[0m-turbo\u001b[1m)\u001b[0m                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModelProviderError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/models/openai/chat.py:322\u001b[0m, in \u001b[0;36mOpenAIChat.invoke\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format must be a subclass of BaseModel if structured_outputs=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_client()\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    323\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    324\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_message(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_kwargs,\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RateLimitError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/models/openai/chat.py:138\u001b[0m, in \u001b[0;36mOpenAIChat.get_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     client_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m OpenAIClient(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_client.py:116\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModelProviderError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     agno_basic_test()\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36magno_basic_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mOpenAIChat(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[1;32m      5\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m     markdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Step 2: Run a basic prompt\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize why Central Park is a great place to visit in NYC.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Agno is installed and running!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResponse from Agent:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/agent/agent.py:1197\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, message, stream, user_id, session_id, audio, images, videos, files, messages, stream_intermediate_steps, retries, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     log_error(\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_attempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attempts. Last error using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_exception\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_exception\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1196\u001b[0m     )\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_exception\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_attempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attempts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/agent/agent.py:1167\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, message, stream, user_id, session_id, audio, images, videos, files, messages, stream_intermediate_steps, retries, **kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1154\u001b[0m             resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\n\u001b[1;32m   1155\u001b[0m                 message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   1156\u001b[0m                 stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1166\u001b[0m             )\n\u001b[0;32m-> 1167\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(resp)\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ModelProviderError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1169\u001b[0m     log_warning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_attempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/agent/agent.py:811\u001b[0m, in \u001b[0;36mAgent._run\u001b[0;34m(self, message, stream, session_id, user_id, audio, images, videos, files, messages, stream_intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_run_response(\n\u001b[1;32m    805\u001b[0m                     content\u001b[38;5;241m=\u001b[39mmodel_response_chunk\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[1;32m    806\u001b[0m                     event\u001b[38;5;241m=\u001b[39mRunEvent\u001b[38;5;241m.\u001b[39mtool_call_completed,\n\u001b[1;32m    807\u001b[0m                     session_id\u001b[38;5;241m=\u001b[39msession_id,\n\u001b[1;32m    808\u001b[0m                 )\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# Get the model response\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mresponse(messages\u001b[38;5;241m=\u001b[39mrun_messages\u001b[38;5;241m.\u001b[39mmessages)\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;66;03m# Format tool calls if they exist\u001b[39;00m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_response\u001b[38;5;241m.\u001b[39mtool_calls:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/models/base.py:187\u001b[0m, in \u001b[0;36mModel.response\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m    183\u001b[0m model_response \u001b[38;5;241m=\u001b[39m ModelResponse()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# Get response from model\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     assistant_message, has_tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_model_response(\n\u001b[1;32m    188\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    189\u001b[0m         model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Handle tool calls if present\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_tool_calls:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;66;03m# Prepare function calls\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/models/base.py:323\u001b[0m, in \u001b[0;36mModel._process_model_response\u001b[0;34m(self, messages, model_response)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m    322\u001b[0m assistant_message\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mstart_timer()\n\u001b[0;32m--> 323\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m    324\u001b[0m assistant_message\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mstop_timer()\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Parse provider response\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/agno/models/openai/chat.py:363\u001b[0m, in \u001b[0;36mOpenAIChat.invoke\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    362\u001b[0m     log_error(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from OpenAI API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelProviderError(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e), model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mModelProviderError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "def agno_basic_test():\n",
    "    # Step 1: Create a simple Agent\n",
    "    agent = Agent(\n",
    "        model=OpenAIChat(id=\"gpt-3.5-turbo\"), \n",
    "        description=\"You are a helpful assistant.\", \n",
    "        markdown=True\n",
    "    )\n",
    "    \n",
    "    # Step 2: Run a basic prompt\n",
    "    response = agent.run(\"Summarize why Central Park is a great place to visit in NYC.\")\n",
    "    \n",
    "    print(\"✅ Agno is installed and running!\")\n",
    "    print(\"\\nResponse from Agent:\\n\")\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agno_basic_test()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
